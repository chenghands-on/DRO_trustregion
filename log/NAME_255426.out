Sender: LSF System <lsfadmin@gauss01>
Subject: Job 255426: <DROSGD> in cluster <cjdx.cluster> Exited

Job <DROSGD> was submitted from host <alpha02> by user <xiechenghan> in cluster <cjdx.cluster> at Thu May 18 19:13:14 2023
Job was executed on host(s) <gauss01>, in queue <gauss>, as user <xiechenghan> in cluster <cjdx.cluster> at Thu May 18 19:13:15 2023
</nfsshare/home/xiechenghan> was used as the home directory.
</nfsshare/home/xiechenghan/DRO_trustregion> was used as the working directory.
Started at Thu May 18 19:13:15 2023
Terminated at Thu May 18 19:14:27 2023
Results reported at Thu May 18 19:14:27 2023

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#/bin/bash
#BSUB -J DROSGD
#BSUB -e /nfsshare/home/xiechenghan/DRO_trustregion/log/NAME_%J.err
#BSUB -o /nfsshare/home/xiechenghan/DRO_trustregion/log/NAME_%J.out
#BSUB -n 1
#BSUB -q gauss
#BSUB -gpu "num=1:mode=exclusive_process"
python my_train.py --optim sgd
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   687.10 sec.
    Max Memory :                                 1565 MB
    Average Memory :                             1413.00 MB
    Total Requested Memory :                     -
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                154
    Run time :                                   78 sec.
    Turnaround time :                            73 sec.

The output (if any) follows:

{
  "eta": 0.08,
  "beta1": 50,
  "beta2": 30,
  "zeta1": 0.25,
  "zeta2": 0.75
}
{
  "qp_rate": 0.3,
  "qp_freq": 1,
  "decay_mode": 1,
  "decay_window": 8000,
  "decay_step": 500.0,
  "decay_radius_step": 0.2,
  "decay_sin_rel_max": 100000000.0,
  "decay_sin_min_scope": 0,
  "decay_sin_max_scope": 37600
}
Using [cuda] for the work
train from scratch!
-----------------------epoch 1-----------------------
-----------current learning rate: 0.001000-----------
training || loss:0.0264903 MAE:65.85189 [32/165515]
training || loss:0.0018649 MAE:15.59557 [3232/165515]
training || loss:0.0012799 MAE:11.91435 [6432/165515]
training || loss:0.0013103 MAE:11.32791 [9632/165515]


PS:

Read file </nfsshare/home/xiechenghan/DRO_trustregion/log/NAME_255426.err> for stderr output of this job.

